{"metadata":{"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Documentation \n[Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/index.html#api \"Pandas Documentation\")</br>\n[Scikit-Learn Documentation](https://scikit-learn.org/stable/supervised_learning.html \"Scikit-Learn Documentation\")</br>\n[NumPy Documentation](https://numpy.org/doc/ \"NumPy Documentation\")</br>\n[Python Tutor](https://pythontutor.com/visualize.html#mode=edit \"Python Tutor\")</br>\n","metadata":{},"id":"e76ece59-eac7-4bb2-87f2-9f78867642cf"},{"cell_type":"code","source":"!pip install openpyxl","metadata":{},"execution_count":null,"outputs":[],"id":"42dc59bb-e858-4f10-9baa-d59270b86495"},{"cell_type":"code","source":"import pandas as pd","metadata":{},"execution_count":null,"outputs":[],"id":"f8e9a771-497c-4955-87aa-ce821f6e516b"},{"cell_type":"code","source":"file_url = 'PUT_THE_URL_TO_THE_DATA_HERE'\ndf = pd.read_excel(file_url)","metadata":{},"execution_count":null,"outputs":[],"id":"1cfbf4de-0f0f-4896-ac0a-d93aeb441787"},{"cell_type":"code","source":"# load dataset\nfilename = 'pima-indians-diabetes.data.csv'\ncol_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndf = pd.read_csv(filename, names=col_names,sep=',')","metadata":{},"execution_count":null,"outputs":[],"id":"f5ce34a2-33a0-450d-9d30-cc866fdf6c64"},{"cell_type":"markdown","source":"## Add or Change Headers","metadata":{},"id":"9a0a8465-cce7-4cf9-b72b-154f21ef1f59"},{"cell_type":"raw","source":"#add header row when creating DataFrame\ndf = pd.DataFrame(data=[data_values],\n                  columns=['col1', 'col2', 'col3'])\n\n#add header row after creating DataFrame\ndf = pd.DataFrame(data=[data_values])\ndf.columns = ['A', 'B', 'C']\n\n#add header row when importing CSV\ndf = pd.read_csv('data.csv', names=['A', 'B', 'C'])","metadata":{},"id":"5849305d-2d16-4729-873a-e5ad75c9a166"},{"cell_type":"markdown","source":"## Basic Data Info","metadata":{},"id":"2f3418cc-6f3f-49f6-b106-ae88bec6405a"},{"cell_type":"code","source":"# Basic Data Cleaning\ndf.columns = df.columns.str.lower().str.replace(' ', '_') # A\n \nstring_columns = list(df.dtypes[df.dtypes == 'object'].index) # B\n \nfor col in string_columns:\n    df[col] = df[col].str.lower().str.replace(' ', '_') # C","metadata":{},"execution_count":null,"outputs":[],"id":"b71e37a1-ab93-4a59-84e7-725b711af521"},{"cell_type":"code","source":"df.shape","metadata":{},"execution_count":null,"outputs":[],"id":"ae15103a-c2cc-4865-8e6e-3cd0ff491277"},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[],"id":"3696fa2d-2f32-4b35-a9e9-a0975f863737"},{"cell_type":"code","source":"df.nunique()","metadata":{},"execution_count":null,"outputs":[],"id":"bc492a21-e2a1-42b8-9210-ed45714de23d"},{"cell_type":"markdown","source":"## Handle your duplicates","metadata":{},"id":"85a2b99e-6e27-48d6-ae39-5a5682affc94"},{"cell_type":"code","source":"# Duplicates in the Columns?\ndf.duplicated()\ndf.duplicated().sum()","metadata":{},"execution_count":null,"outputs":[],"id":"1ad8fbd3-56ce-46d3-8786-16bc3fc8a0ae"},{"cell_type":"code","source":"# df[['InvoiceNo', 'StockCode', 'InvoiceDate', 'CustomerID']]","metadata":{},"execution_count":null,"outputs":[],"id":"564b17a3-ecc4-4ca7-86fc-040459b0f289"},{"cell_type":"code","source":"# Duplicated Rows?\ndf[df.duplicated()]","metadata":{},"execution_count":null,"outputs":[],"id":"8a55a1ba-0a4d-4baa-ad2c-ec0a45f37d16"},{"cell_type":"code","source":"# Find duplicates in specific columns from your dataset.  Replace with your columns obviously.  keep the first or last dupe.\n# df.loc[df.duplicated(keep='last'), ['InvoiceNo', 'StockCode', 'InvoiceDate', 'CustomerID']]","metadata":{},"execution_count":null,"outputs":[],"id":"12f8ec9e-8523-4e49-9202-61dda05e4a34"},{"cell_type":"code","source":"# df_unique = df.drop_duplicates(keep='first')\ndf.drop_duplicates(keep='first')","metadata":{},"execution_count":null,"outputs":[],"id":"93d3b09c-5721-4dd5-bffc-fd496ce9b984"},{"cell_type":"code","source":"# Only consider duplicates in these columns and drop only them\n# df.duplicated(subset=['InvoiceNo', 'StockCode', 'InvoiceDate','CustomerID'], keep='first').sum()\n# By looking only at these four columns instead of all of them, we can see that the number of duplicate rows may increase/decrease\n# This means that there are rows that have the exact same values as these four columns but have different values in \n# other columns, which means they may be different records. \n# In most cases, it is better to use all the columns to identify duplicate records.","metadata":{},"execution_count":null,"outputs":[],"id":"33160297-a412-4021-93a7-4f1dbe9547f6"},{"cell_type":"markdown","source":"## Analyze the Data Types in your dataset","metadata":{},"id":"9b73eda3-34ae-4b5f-898d-a66eadab9b1f"},{"cell_type":"code","source":"df.dtypes","metadata":{},"execution_count":null,"outputs":[],"id":"c3b34ba1-5ede-47e9-a725-7cf555863a0c"},{"cell_type":"code","source":"# Change the data type of any field with this:\ndf['Country'] = df['Country'].astype('category')\ndf.dtypes\n# This options are:  bool, str, int, float, category... etc.\n# This is useful if you want to convert a binary classification target to 0/1 - convert it's type to int... esp if it is float","metadata":{},"execution_count":null,"outputs":[],"id":"6b7d9657-ad59-4383-9a5f-42622ad6f79b"},{"cell_type":"code","source":"# View your categorial types:\ndf['Country'].cat.categories","metadata":{},"execution_count":null,"outputs":[],"id":"dbde5c61-c15a-4734-b755-0fd6aaba0b7b"},{"cell_type":"markdown","source":"## Treat incorrect values in your dataset\nReplace Numerics and replace Categorical data","metadata":{},"id":"ce5d41d2-6635-4809-8d44-f5876f2f44ab"},{"cell_type":"code","source":"# If you have values in your columns that you want to replace - use this for loop\n# For instance - in the CreditScoring dataset - there are numerous 99999999 that need to be replaced\n\n# for c in ['income', 'assets', 'debt']:\n#    df[c] = df[c].replace(to_replace=99999999, value=np.nan)","metadata":{},"execution_count":null,"outputs":[],"id":"95838f92-00a3-431b-9cb9-46ea8e5a01eb"},{"cell_type":"code","source":"# If you want to remove a value from a column - use this: \n# df = df[df.status != 'unk']   # This removes the value 'unk' from your data in the column.  Modify as needed","metadata":{},"execution_count":null,"outputs":[],"id":"4117acd6-da61-4526-b6ee-12d29fd98446"},{"cell_type":"code","source":"# If you need to search through a column and find a value in a string:\n# df[df['State'].str.contains('il', na=False)]\n# df['State'].unique()\n\n# another technique to search and replace strings:\n# df.loc[df['StockCodeDescription'].str.contains('MISEL', na=False),]\n# df['StockCodeDescription'] = df['StockCodeDescription'].str.replace('MISELTOE', 'MISTLETOE')","metadata":{},"execution_count":null,"outputs":[],"id":"e67d2765-fbd3-4100-8103-a3933b0e00d5"},{"cell_type":"code","source":"# Here is another technique to search and replace in a string:\n# Create a mask\nil_mask = df['State'].isin(['il', 'Il', 'iL', 'Il']) # This is saying il, Il, iL, Il are all in the STATE column\nil_mask.sum()\ndf.loc[il_mask, 'State'] = 'IL'   # subset the mask and replace all instances with IL","metadata":{},"execution_count":null,"outputs":[],"id":"81fd4f4b-ca3f-4d68-9fb3-be707d67fd67"},{"cell_type":"markdown","source":"## Missing Values","metadata":{},"id":"f561c046-93e9-4627-ae69-ae4f9b6812ea"},{"cell_type":"code","source":"df.isna()","metadata":{},"execution_count":null,"outputs":[],"id":"b186e745-4a33-47cf-bd1e-82091e4c0450"},{"cell_type":"code","source":"df.isna().sum()","metadata":{},"execution_count":null,"outputs":[],"id":"4fb5e2de-a3eb-4230-8156-1fbddf50dea3"},{"cell_type":"code","source":"# Check for missing values in a single column\n# df[df['Description'].isna()]","metadata":{},"execution_count":null,"outputs":[],"id":"81fb7ec2-edb1-4f4d-8ff3-115f6483ca01"},{"cell_type":"code","source":"# List all rows that are missing a value in this field\n# df.dropna(subset=['Description'])  ","metadata":{},"execution_count":null,"outputs":[],"id":"a5a90252-c290-4b05-9edc-476dd4c39f99"},{"cell_type":"code","source":"# Drop all rows that are missing a value in this field:\n# df.dropna(subset=['Description'], inplace=True)","metadata":{},"execution_count":null,"outputs":[],"id":"7e7dd88c-4394-48ff-a242-2724cac7e041"},{"cell_type":"code","source":"# df.isna().sum()","metadata":{},"execution_count":null,"outputs":[],"id":"29498a58-3257-4b92-8ec8-bd85ba7bda53"},{"cell_type":"markdown","source":"### Impute Values instead of dropping them","metadata":{},"id":"2e76243f-a7ea-43a0-a86a-fccf1f75acb0"},{"cell_type":"code","source":"# df['CustomerID'].fillna('Missing', inplace=True)","metadata":{},"execution_count":null,"outputs":[],"id":"3f25928c-57a1-4e97-a10c-f851ce637578"},{"cell_type":"code","source":"# Replace NaN one column with the median\n# df['col1'] = df['col1'].fillna(df['col1'].median())\n# df = df.fillna(df.median())","metadata":{},"execution_count":null,"outputs":[],"id":"b152a366-3889-453c-b470-380dd2b03b25"},{"cell_type":"markdown","source":"## Save your dataframe to a CSV - don't forget to download the CSV","metadata":{},"id":"9faba3ac-aae6-4d37-9467-a33c3dc69ecf"},{"cell_type":"code","source":"# saving the dataframe\n# df.to_csv('file1.csv')","metadata":{},"execution_count":null,"outputs":[],"id":"2dbfdd1a-7066-4895-bcad-a8bc34038750"},{"cell_type":"code","source":"For a small dataframe - consider saving it as an image:\npip install dataframe-image\n \nimport pandas as pd\nimport dataframe_image as dfi\n \ndf = pd.DataFrame({'A': [1,2,3,4],\n                   'B':['A','B','C','D']})\n \ndfi.export(df, 'dataframe.png')","metadata":{},"execution_count":null,"outputs":[],"id":"adfaae10-6673-4aa0-b23c-f70c37ac7953"}]}