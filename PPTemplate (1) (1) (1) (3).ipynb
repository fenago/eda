{"metadata":{"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pre-Processing Template","metadata":{},"id":"d4dace8a-a7c2-4a1f-bab7-67cd19581aae"},{"cell_type":"markdown","source":"## Load your common imports","metadata":{},"id":"b8d030dc-35b9-4bd1-bea8-2aa6142908e9"},{"cell_type":"code","source":"# Python ≥3.5 is required\nimport sys\nassert sys.version_info >= (3, 5)\n\n# Scikit-Learn ≥0.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\n# Common imports\n#Import your Libraries\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport sklearn.metrics as metrics\n%matplotlib inline\n\n# if you get any errors - make sure you do a !pip install xxxx","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"61c8a4f4-6500-469b-ab1b-3184a9c116fe"},{"cell_type":"markdown","source":"## Load your dataset","metadata":{},"id":"d5d722c7-73a7-40fc-926c-da70b2a87377"},{"cell_type":"code","source":"# %%timeit -n 1\n# df = pd.read_csv('./data/<put your data here>')\n# TODO: CREATE AN EXAMPLE WITH EXCEL AND ONE WITH SEP\ndf = pd.read_csv(\"https://raw.githubusercontent.com/fenago/regress/main/data/data.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"db8759b4-9782-415f-baa5-23858ad4f282"},{"cell_type":"code","source":"# Eyeball your data\ndf.sample(3)","metadata":{},"execution_count":null,"outputs":[],"id":"9bfc450d-9a1e-46e8-b4f4-9d6f26531a3e"},{"cell_type":"markdown","source":"## Basic Data Cleaning","metadata":{},"id":"4bf20d6a-4ad5-478c-b868-4bb7790abb13"},{"cell_type":"code","source":"# Basic Data Cleaning\n# Replace spaces in column names with an underscore\n# Make all column names lower case\ndf.columns = df.columns.str.lower().str.replace(' ', '_') # A\n\nstring_columns = list(df.dtypes[df.dtypes == 'object'].index) # B\n \nfor col in string_columns:\n    df[col] = df[col].str.lower().str.replace(' ', '_') # C","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"ba208dcf-6abe-4cb4-a49a-8657ed6cc55f"},{"cell_type":"code","source":"# Replace WHITE SPACE in the column names\nfor col in string_columns:\n    if df[col].nunique():\n        df[col] = df[col].str.strip()\n        # print(df[col].head(1))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"60d29984-c853-4f33-b5ad-11f5e1ff7d17"},{"cell_type":"code","source":"len(df)","metadata":{},"execution_count":null,"outputs":[],"id":"87655188-067f-4110-9f2a-2298db667532"},{"cell_type":"code","source":"df.describe()","metadata":{},"execution_count":null,"outputs":[],"id":"ef1e5314-559c-45d6-b14a-845787ca5d50"},{"cell_type":"code","source":"df.shape","metadata":{},"execution_count":null,"outputs":[],"id":"2681b7f8-b08e-437d-b8d8-2b79fb2ef9f4"},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[],"id":"a520eb81-8cf4-458e-a74a-f1cbefdc0db4"},{"cell_type":"code","source":"df.nunique()","metadata":{},"execution_count":null,"outputs":[],"id":"1aeb0cb9-df29-492f-bad8-763da1a2261c"},{"cell_type":"code","source":"df.corr()","metadata":{},"execution_count":null,"outputs":[],"id":"8300ae87-cf31-4a8c-aaa5-24075409c991"},{"cell_type":"markdown","source":"## Remove all duplicates","metadata":{},"id":"3254669f-e0f8-4627-bf95-3cfbf1aa7f68"},{"cell_type":"code","source":"print(df.duplicated().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"ea607cbc-c174-4bdf-a4da-ee76c0a9b706"},{"cell_type":"code","source":"# The Pandas .drop_duplicates() method\ndf = df.drop_duplicates(\n    subset=None,            # Which columns to consider \n    keep='first',           # Which duplicate record to keep\n    inplace=False,          # Whether to drop in place\n    ignore_index=False      # Whether to relabel the index\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"6581dbce-cda7-4027-80b1-fa56d8481c76"},{"cell_type":"code","source":"print(df.duplicated().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"8abf250a-88c0-4420-8434-5623858a3d15"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"ca59f38a-3763-4db3-aeb1-708edc492b33"},{"cell_type":"markdown","source":"## Deal with Nulls","metadata":{},"id":"779364cd-0ec0-4ed7-ac38-c4dd29eb0213"},{"cell_type":"code","source":"# Identify which columns have nulls\nprint(df.isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"004dcee5-0985-4c62-821a-7ce20528d32b"},{"cell_type":"markdown","source":"#### Note from Dr. Lee:\nWhen you have null values, you are left with essentially 4 options:\n   - Drop the Feature/Column\n   - Drop the Rows\n   - Impute\n   - Replace\n    \n*important, pick only one of these 4 options per feature!","metadata":{},"id":"82b57d8b-2b18-477d-be1e-9451d82c382f"},{"cell_type":"markdown","source":"### Option 1 and 2:  Drop the Feature and/or Rows","metadata":{},"id":"00fa049e-5e82-482d-8828-87c0b2b3f297"},{"cell_type":"code","source":"# Exploring the Pandas .dropna() method\ndf.dropna(\n    axis=0,         # Whether to drop rows or columns\n    how='any',      # Whether to drop records if 'all' or 'any' records are missing\n    thresh=None,    # How many columns/rows must be missing to drop\n    subset=None,    # Which rows/columns to consider\n    inplace=False   # Whether to drop in place (i.e., without needing to re-assign)\n)\n# you can just call df.dropna() and it will call with these defaults\n# thresh=: the number of items that must be empty\n# subset=: the names of columns to look at when considering missing values","metadata":{},"execution_count":null,"outputs":[],"id":"b6881244-0886-4fbc-850d-737a7e392740"},{"cell_type":"code","source":"# drop the duplicated column \"market_category\" - it can be comma separated\ndf = df.drop(columns=\"market_category\")","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"68cc4098-7546-4520-872d-d2a31aaf4baa"},{"cell_type":"code","source":"# I would most likely always run this cell\n# Dropping Records Only if All Records are Missing\ndf = df.dropna(how='all')\n# print(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"ec3e5cf5-91fa-4de6-bab6-ce6f77e3d47e"},{"cell_type":"markdown","source":"### Option 3: Impute","metadata":{},"id":"06f3ff43-40cb-4f6f-b911-b5540355b275"},{"cell_type":"markdown","source":"Missing values often plague data, and given that there are not too many of them, they can be imputed (filled in).\nBefore using KNN and other distance-based algorithms, the data needs to be scaled or normalized to eliminate differences in scale (for example, one column representing number of children and another representing annual salary — these values cannot be taken at face value). Using KNN imputing follows the following process:\n- Scale/normalize the data.\n- KNN-impute to fill in missing values.\n- Inverse scale/normalize the data.","metadata":{},"id":"2b7238ea-9f72-45ad-aa35-e953c6ab112a"},{"cell_type":"markdown","source":"\nSimple Imputing Methods are statistical constant measures like the mean or the median which fills in NaN (missing values) with the statistical measure of each column. The parameter strategy can be substituted with ‘mean’, ‘median’, ‘most_frequent’ (mode), or ‘constant’ (a manual value with parameter fill_value).\n\nValueError: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'bmw'","metadata":{},"id":"57f11cc3-ec09-49c3-b55c-a85bd0a6eb6c"},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='mean')\ndata = imputer.fit_transform(df)","metadata":{},"execution_count":null,"outputs":[],"id":"2a899520-1549-42d1-90ab-a4250f1fc847"},{"cell_type":"markdown","source":"KNN Imputing is the most popular and complex method for imputing missing values, in which the KNN algorithm finds other data points similar to one with a missing value within multidimensional space.","metadata":{},"id":"d8b77f0b-a6e7-443a-9a5b-a2afa063a7ea"},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\nimputer = KNNImputer()\ndata = imputer.fit_transform(df)","metadata":{},"execution_count":null,"outputs":[],"id":"b361a729-1e71-4d3d-8b74-b8eee1e58c11"},{"cell_type":"markdown","source":"### Option 4:  Replace / fillna()","metadata":{},"id":"347daded-56b7-4467-ae49-a10d23e360d8"},{"cell_type":"code","source":"# For instance - in the CreditScoring dataset - there are numerous 99999999 that need to be replaced\n# Obviously don't run this with your dataset\n# for c in ['income', 'assets', 'debt']:\n#    df[c] = df[c].replace(to_replace=99999999, value=np.nan)\n#df = df[df.status != 'unk']   # Also make sure to treat the target variable\n\n# \n\n# df['TotalCharges'] = df['TotalCharges'].fillna(0)","metadata":{},"execution_count":null,"outputs":[],"id":"ddff34e8-97e4-492e-97a4-1349cc14392a"},{"cell_type":"markdown","source":"## Outlier Detection","metadata":{},"id":"316154f2-e008-4295-bead-2b09e5e3febd"},{"cell_type":"markdown","source":"Isolation Forest is an algorithm to return the anomaly score of a sample. The algorithm isolates observations by creating paths by randomly selecting a feature, randomly selecting a split value, the path length representing its normality. Shorter paths represent anomalies — when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies.  The output of predictions of the anomaly detector is an array of scores from -1 to 1, positive scores representing higher chances of being anomalies.\n\nOnly works on scaled and encoded data (like Impute)","metadata":{},"id":"326e7b8b-7f21-48c7-8d11-98bad120246a"},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\nidentifier = IsolationForest().fit(X)\nidentifier.predict(X)","metadata":{},"execution_count":null,"outputs":[],"id":"7a75bcf2-5f65-4328-8bb6-301c33769ba7"},{"cell_type":"markdown","source":"One Class SVM is another unsupervised method for detecting outliers, suited for high-dimensional distributions where an anomaly detection method like Isolation Forest would develop too much variance.","metadata":{},"id":"4c1dfa30-2aeb-4791-8a45-301bb43d1436"},{"cell_type":"code","source":"from sklearn.svm import OneClassSVM\nidentifier = OneClassSVM().fit(X)\nidentifier.predict(X)","metadata":{},"execution_count":null,"outputs":[],"id":"2da78447-e227-4e55-93ab-b85eca3c014e"},{"cell_type":"markdown","source":"Local Outlier Factor is the third of three commonly used outlier identifiers. The anomaly score of each sample — the Local Outlier Factor — measures the local deviation of density given a sample with respect to its neighbors. Based on the K-Nearest Neighbors, samples that have substantially lower density than their neighbors are considered outliers.\nBecause this algorithm is distance based, the data needs to be scaled or normalized before it is used. This algorithm can be seen as a non-linear high-variance alternative to Isolation Forest.","metadata":{},"id":"ec385eda-0a63-4203-b14e-6c5d27cb2711"},{"cell_type":"code","source":"from sklearn.neighbors import LocalOutlierFactor\nmodel = LocalOutlierFactor().fit(X)\nmodel.predict(X)","metadata":{},"execution_count":null,"outputs":[],"id":"669d2048-71bc-4808-870d-50ec0ba9a44b"},{"cell_type":"markdown","source":"For all three anomaly algorithms, it is the data scientist’s choice to eliminate all anomalies. Be sure that anomalies are not just data clusters themselves — make sure that the number of anomalies are not too excessive in number. A PCA visualization can confirm this.","metadata":{},"id":"dbf9bb4c-e08d-45b4-938d-e4b726e3fc1c"},{"cell_type":"markdown","source":"## Fix all Data Types","metadata":{},"id":"9777c5e5-ad4f-485f-9776-ac04b3cf4a1d"},{"cell_type":"code","source":"df.head(1).T","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"0d8fbeba-e65d-431e-858b-4bd6eadf760e"},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"90857cda-51ae-45a0-9b93-35336d31bd40"},{"cell_type":"code","source":"# Change columns to a certain datatype (avoid category datatype)\n# You may have to run this several times for each datatype\ncols_to_include = ['year', 'number_of_doors', 'engine_cylinders', 'engine_hp']\nfor col in df.columns:\n    if df[col].nunique() and col in cols_to_include:\n        df[col] = df[col].astype('object')","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"58c58178-0d8a-43cc-b8ae-5757d99af700"},{"cell_type":"code","source":"# df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n# You can also convert objects to numeric one column at a time\n\n# OR - if you have a binary column - you can use this template\n# df.churn = (df.churn == 'yes').astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"7ceb305b-c401-487b-92c7-1024e5613873"},{"cell_type":"code","source":"# %%timeit\nunique_counts = pd.DataFrame.from_records([(col, df[col].nunique()) for col in df.columns],\n                          columns=['Column_Name', 'Num_Unique']).sort_values(by=['Num_Unique'])\nunique_counts","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"4fc2ef0a-dade-4192-b590-daa9e8d7954e"},{"cell_type":"code","source":"from sklearn.compose import make_column_selector as selector\n\nnumerical_columns_selector = selector(dtype_exclude=object)\ncategorical_columns_selector = selector(dtype_include=object)\n\nnumerical_columns = numerical_columns_selector(df)\ncategorical_columns = categorical_columns_selector(df)\nprint(categorical_columns)\nprint(numerical_columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"8320fdc7-a28b-41f5-9971-21f3273db2b6"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"5e41a5f7-c55b-4cc0-981e-d271213b2644"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"33305531-7e7d-4f7c-bc99-61837c118b75"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"2b2c6351-dc2d-454c-a494-b13972f6c5f4"},{"cell_type":"markdown","source":"## Drop columns","metadata":{},"id":"28fab38b-c247-4428-80c7-9189b0b8018e"},{"cell_type":"code","source":"# drop the duplicated column `\"education-num\"` \n# df = df.drop(columns=\"education-num\")","metadata":{},"execution_count":null,"outputs":[],"id":"0504e89e-0e13-4f88-965c-113b0310dc69"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"673e758f-d466-4892-bd24-fa6e2b4c9f82"},{"cell_type":"markdown","source":"## Replace Values","metadata":{},"id":"c33c9e4a-1984-44eb-ad04-59ff27316a2f"},{"cell_type":"code","source":"# MAKE SURE THAT YOU WRANGLE YOUR DATA.  THIS IS AN EXAMPLE OF THE TYPES OF THINGS THAT ARE NEEDED\n# SKIP THIS CEL - IT IS ONLY TO REITERATE THE NEED TO CLEAN \n# For instance - in the CreditScoring dataset - there are numerous 99999999 that need to be replaced\n# Obviously don't run this with your dataset\n# for c in ['income', 'assets', 'debt']:\n#    df[c] = df[c].replace(to_replace=99999999, value=np.nan)\n#df = df[df.status != 'unk']   # Also make sure to treat the target variable","metadata":{},"execution_count":null,"outputs":[],"id":"eefa1acf-55a8-4035-9ae8-fab001cc512a"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"d64d7ed3-61c4-4749-8255-8563cca80758"},{"cell_type":"markdown","source":"## Categorical Analysis (Mutual Information)","metadata":{},"id":"282d22ce-9de2-4611-b49c-ceac0a8e83fa"},{"cell_type":"code","source":"from IPython.display import display\ntarget_name = \"msrp\"","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"968de41b-c3ad-4503-a158-98a0c066c229"},{"cell_type":"code","source":"global_mean = df[target_name].mean()\nglobal_mean","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"94778815-cf2e-4ffb-ad8f-56d49e044135"},{"cell_type":"code","source":"for col in categorical_columns:\n    df_group = df[categorical_columns].groupby(by=col).msrp.agg(['mean'])\n    df_group['diff'] = df_group['mean'] - global_mean\n    df_group['risk'] = df_group['mean'] / global_mean\n    display(df_group)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"b302b0e3-6aab-4d3c-acfa-0ea001fa4540"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"19f30f2a-b88b-42bd-bfa8-f43303c5f984"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"7ebc257d-20c9-4242-81e0-efc83128f3d3"},{"cell_type":"code","source":"target_name = \"msrp\"\ny = df[target_name]\nX = df.drop(columns=[target_name])","metadata":{},"execution_count":null,"outputs":[],"id":"57afd2a8-4462-4e49-b03f-e8af3f3f5185"},{"cell_type":"code","source":"df.dtypes","metadata":{},"execution_count":null,"outputs":[],"id":"30a12035-6f34-4f52-b41d-125aabecddfc"},{"cell_type":"code","source":"# %%timeit\nunique_counts = pd.DataFrame.from_records([(col, df[col].nunique()) for col in df.columns],\n                          columns=['Column_Name', 'Num_Unique']).sort_values(by=['Num_Unique'])","metadata":{},"execution_count":null,"outputs":[],"id":"0ffce050-5462-4929-a433-7d606312744f"},{"cell_type":"code","source":"unique_counts","metadata":{},"execution_count":null,"outputs":[],"id":"1a0c3275-4d5b-4b72-b544-cd6189016998"},{"cell_type":"markdown","source":"The simplest way to convert a column to a categorical type is to use astype('category') . We can use a loop to convert all the columns we care about using astype('category').\n\nThis code snippet can be reused to to change all of the data types to the correct data type.  I would not use \"category\" as data type because it will get missed later because of the technique used.\nPython Data Types\n![Python Data Types](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F3576%2F1*QfI8H_8HplGa1v9IrrWjBA.png&f=1&nofb=1 \"Python Data Types\")\nPandas Data Types\n![Pandas Data Types](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fcdn-images-1.medium.com%2Fmax%2F2000%2F1*wrXMq7iTWih7lsBBRQFxXg.png&f=1&nofb=1 \"Pandas Data Types\")","metadata":{},"id":"93b1055d-6b66-4ea4-9b48-96a34c0455ae"},{"cell_type":"code","source":"cols_to_include = ['year', 'number_of_doors', 'engine_cylinders', 'engine_hp']\nfor col in df.columns:\n    if df[col].nunique() and col in cols_to_include:\n        df[col] = df[col].astype('object')","metadata":{},"execution_count":null,"outputs":[],"id":"cb757ef0-ea75-460b-8c48-30fb8180add2"},{"cell_type":"code","source":"df.dtypes","metadata":{},"execution_count":null,"outputs":[],"id":"97b0f24a-3f96-4efc-99c5-8501aa5ba3c0"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"45ce9218-ffd3-4943-80b7-9a968885211b"},{"cell_type":"code","source":"from sklearn.compose import make_column_selector as selector\n\nnumerical_columns_selector = selector(dtype_exclude=object)\ncategorical_columns_selector = selector(dtype_include=object)\n\nnumerical_columns = numerical_columns_selector(df)\ncategorical_columns = categorical_columns_selector(df)","metadata":{},"execution_count":null,"outputs":[],"id":"6f9eccf9-a950-46b8-9909-b99e2191de5a"},{"cell_type":"code","source":"print(\"categorical columns: \", categorical_columns)\nprint(\" \")\nprint(\"numerical columns: \", numerical_columns)","metadata":{},"execution_count":null,"outputs":[],"id":"5054449e-33be-4896-9cf7-e8ac0a2eb70c"},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, StandardScaler\n\ncategorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\nnumerical_preprocessor = StandardScaler()","metadata":{},"execution_count":null,"outputs":[],"id":"fb37e148-73ef-4e43-b88d-d61b972daec7"},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\n\npreprocessor = ColumnTransformer([\n    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n    ('standard_scaler', numerical_preprocessor, numerical_columns)])","metadata":{},"execution_count":null,"outputs":[],"id":"7b4aa914-dbac-41e0-9c8a-e58ebde5d142"},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline\n\nmodel = make_pipeline(preprocessor, LinearRegression())","metadata":{},"execution_count":null,"outputs":[],"id":"40b62ee3-f4a0-4189-963c-37c4563ea980"},{"cell_type":"code","source":"from sklearn import set_config\nset_config(display='diagram')\nmodel","metadata":{},"execution_count":null,"outputs":[],"id":"2a70e7a8-3471-4fd9-9d67-49f1350fe0df"},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndata_train, data_test, target_train, target_test = train_test_split(\n    df, y, random_state=42)","metadata":{},"execution_count":null,"outputs":[],"id":"2be2a8c1-62ad-4d87-81a2-50e7b26b58c9"},{"cell_type":"code","source":"%%time\n_ = model.fit(data_train, target_train)","metadata":{},"execution_count":null,"outputs":[],"id":"7dac6c5c-7acc-4826-9eb8-9dea0c30b43a"},{"cell_type":"code","source":"data_test.head()","metadata":{},"execution_count":null,"outputs":[],"id":"b8bebd78-46c3-465b-b8b0-8a629c41ef4a"},{"cell_type":"code","source":"model.predict(data_test)[:5]","metadata":{},"execution_count":null,"outputs":[],"id":"0194613c-3d82-4cde-a324-4d83b0a8fb70"},{"cell_type":"code","source":"target_test[:5]","metadata":{},"execution_count":null,"outputs":[],"id":"53f16287-d8c0-4e47-a85d-4d663d31d29e"},{"cell_type":"code","source":"model.score(data_test, target_test)","metadata":{},"execution_count":null,"outputs":[],"id":"6450c695-1f28-4cae-ab55-0feb3edc5696"},{"cell_type":"code","source":"from sklearn.model_selection import cross_validate\n\ncv_results = cross_validate(model, df, y, cv=5)\ncv_results","metadata":{},"execution_count":null,"outputs":[],"id":"0ce9d9ad-1217-446e-b8dd-3714205a5cc1"},{"cell_type":"code","source":"scores = cv_results[\"test_score\"]\nprint(\"The mean cross-validation accuracy is: \"\n      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")","metadata":{},"execution_count":null,"outputs":[],"id":"3dfe4852-bd33-459a-9995-cf30264bbeb2"},{"cell_type":"code","source":"# Harness","metadata":{},"execution_count":null,"outputs":[],"id":"b9f482a8-49d5-4cc3-b748-a48dc3260ad7"},{"cell_type":"code","source":"from sklearn.metrics import explained_variance_score,mean_absolute_error,r2_score","metadata":{},"execution_count":null,"outputs":[],"id":"4629bcc5-d21f-46c4-8069-a946617c430f"},{"cell_type":"code","source":"from time import time\n\nfrom sklearn.linear_model import LinearRegression, Ridge,Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor","metadata":{},"execution_count":null,"outputs":[],"id":"18710643-6859-48f2-9f2b-cbb9f9cd3f9e"},{"cell_type":"code","source":"regressors = [\n    KNeighborsRegressor(),\n    GradientBoostingRegressor(),\n    ExtraTreesRegressor(),\n    RandomForestRegressor(),\n    DecisionTreeRegressor(),\n    LinearRegression(),\n    Lasso(),\n    Ridge()\n]","metadata":{},"execution_count":null,"outputs":[],"id":"0ea3524b-769c-4ffb-b84f-06da6bb7d1c3"},{"cell_type":"code","source":"head = 10\nfor lr_model in regressors[:head]:\n    start = time()\n    lr_model.fit(data_train, target_train)\n    train_time = time() - start\n    start = time()\n    y_pred = lr_model.predict(X_test)\n    predict_time = time()-start    \n    print(model)\n    print(\"\\tTraining time: %0.3fs\" % train_time)\n    print(\"\\tPrediction time: %0.3fs\" % predict_time)\n    print(\"\\tExplained variance:\", explained_variance_score(y_test, y_pred))\n    print(\"\\tMean absolute error:\", mean_absolute_error(y_test, y_pred))\n    print(\"\\tR2 score:\", r2_score(y_test, y_pred))\n    print()","metadata":{},"execution_count":null,"outputs":[],"id":"b6dc5d44-7c79-4241-b51a-5dadf40d4824"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"4ee40e64-bf1a-46d3-8660-0e054fd9968f"}]}